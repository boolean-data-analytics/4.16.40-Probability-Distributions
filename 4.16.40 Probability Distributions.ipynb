{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6982ba-d01b-4c96-8b23-409477ad5abf",
   "metadata": {},
   "source": [
    "# 4.16.40 Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d843f44-b694-4bb0-b67e-4231591e6655",
   "metadata": {},
   "source": [
    "### A simple coin toss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730e6cb-43b9-463a-a96a-be7d10f544c4",
   "metadata": {},
   "source": [
    "According to Wikipedia: \n",
    "\n",
    "> In probability theory and statistics, a probability distribution is the **mathematical function** that gives the **probabilities of occurrence** of different **possible outcomes** for an **experiment**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13364983-7218-4607-abbe-96f557dc14a0",
   "metadata": {},
   "source": [
    "Let's unpack this statement with an example: \n",
    "\n",
    "- we'll use a simple example like a coin toss, this is the experiment; \n",
    "- there are two possible outcomes: heads and tails; \n",
    "- if the coin is fair, we would say that the probability distribution of the outcome takes the value \n",
    "    - 0.5 in case of heads \n",
    "    - 0.5 in case of tails "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd74c49-7cec-4c13-b766-dfefa364ceb9",
   "metadata": {},
   "source": [
    "In probability theory, an event like a single coin toss is modelled by a **[Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)** (named after the Swiss mathematician Jacob Bernoulli that we met in our first class of this module). More generally (and technically), it is the discrete probability distribution of a random variable which takes the value $1$ with probability $p$ and the value $0$ with probability $q=1-p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830d84b-5910-47d8-b4c3-f1ee9280eb65",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a special case of the **[binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution)** where a single trial is conducted. More specifically, it is the discrete probability distribution of the **number of successes** in a sequence of $n$ independent experiments, each having a success (with probability $p$) or failure (with probability $q = 1 − p$) outcome. \n",
    "\n",
    "So if a single coin toss can be modelled with a Bernoulli distribution, a series of $n$ coin tosses can be modelled with a binomial distribution. \n",
    "\n",
    "The `random` module in our beloved `numpy` library comes with a series of functions that allow us to simulate a process (like a coin toss) that comes from a probability distribution. The `np.random.binomial()` function requires two parameters: \n",
    "\n",
    "- `n` the number of trials\n",
    "- `p` the probability of success\n",
    "\n",
    "As we saw before, the binomial distribution with one single trial (that is, $n=1$), is the Bernoulli distribution, so to simulate a single coin toss with a Bernoulli distribution, we can write: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9005f86-d016-429c-86ac-deff9da2a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae94234-cd95-4483-8ace-b0fe4e81e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(n=1, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1ef79-3e88-4ed1-bd68-5d89dec75167",
   "metadata": {},
   "source": [
    "Unlike [John Edmund Kerrich](https://en.wikipedia.org/wiki/John_Edmund_Kerrich), a mathematician who tossed a coin 10,000 times to prove the asymptotic nature of probability while interned in Nazi-occupied Denmark in the 1940s, we can now use a list comprehension to repeat the experiment as many times as we want. Let's produce 10 coin tosses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a210655-c3f5-4c1e-ad02-1c130e788e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.random.binomial(n=1, p=0.5) for toss in range(11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e7ed2-c0ff-4127-b3ac-cc2cf668e57d",
   "metadata": {},
   "source": [
    "The same result can be achieved by specifying `n=10` in the `np.random.binomial()` formula: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156b573-8bda-4f3f-a313-169a3f9a55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(n=10, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f874cb-8049-4c2f-869e-f87114ea2bf4",
   "metadata": {},
   "source": [
    "Notice that the output of the previous formula is the number of successes; if we wanted a list containing the successes, we could use a list comprehension (as above) or specify `n=1` and `size=10`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77ddb2-4879-4405-9c2b-a1470da9597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial(n=1, p=0.5, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87837b-eb70-47f2-8fa8-72bcf86afdf5",
   "metadata": {},
   "source": [
    "### Selection Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b376fd-4751-48fc-a23b-3997ad55e797",
   "metadata": {},
   "source": [
    "An interesting phenomena in statistics to be wary about is **selection bias**, which refers to the practice of selectively choosing data, consciously or unconsciously, in a way that that leads to a conclusion that is misleading. *Note: there are [many types](https://en.wikipedia.org/wiki/Selection_bias) of selection bias.*\n",
    "\n",
    "A well conducted experiment requires you to formulate an hypothesis and test it, this way you can have high confidence on the solidity of the conclusions. The thing is, often times, looking through a dataset, one tries to discern a pattern, but is the pattern for real or just the product of **data snooping**? There is a saying among statisticians: *If you torture the data long enough, sooner or later it will confess*.\n",
    "\n",
    "Let's try the following thought experiment: \n",
    "\n",
    "1. your friend tells you she can flip a coin and have it land heads on the next 10 tosses \n",
    "2. you accept the bet and she proceeds to toss it 10 times \n",
    "3. they all land heads \n",
    "4. you clearly deduce she has some special talent (the probability of having 10 heads by chance is 1 in 1,000)\n",
    "\n",
    "Now imaginea second scenario: the frontman of a music band at a concert asks its 20,000 fans to toss a coin 10 times each, and report if they get 10 heads in a row. The chance that somebody in the crowd will get 10 heads is now very high. Selecting, after the fact, the fans who got all heads does not mean they have a special talent; it’s most likely luck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65657dff-0b38-4506-906b-6da46a85f812",
   "metadata": {},
   "source": [
    "We can easily run this experiment in Python: \n",
    "\n",
    "- we can use the `np.random.binomial()` function \n",
    "- specify `n=10` to simulate the 10 coin tosses\n",
    "- specify `size=20000` to simulate the 20,000 fans performing the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bcbac3-c137-40eb-94ac-1640565e0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tosses = np.random.binomial(n=10, p=0.5, size=20000)\n",
    "print('Total tosses:', len(tosses))\n",
    "print('First 25 results: ', tosses[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b62649-b908-47dd-8504-43ee2d335f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Out of 20,000 fans tossing 10 coins each,', \n",
    "      len([res for res in tosses if res==10]), \n",
    "      'got 10 heads in a row.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671a1c1-d786-4a61-9ae8-577f9037373e",
   "metadata": {},
   "source": [
    "We can now plot the distribution of these 20k tosses; notice that is is symmetric and centered around the value of 5, that is, 5 heads in 10 coin tosses: $5/10 = 0.5$ which is the exact probability of a fair coin.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d298435-febe-4f3d-b3c0-56e9f251a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [el-0.5 for el in list(set(tosses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4211b-c2ea-4866-8917-47f23fbd22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(tosses, bins = bins, stat='probability', label='samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460708d-634e-4508-8082-1aa8568fbc5b",
   "metadata": {},
   "source": [
    "### The Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac57ef-a101-48be-912a-969dbbe07620",
   "metadata": {},
   "source": [
    "The histogram above has a very carachteristic \"bell shape\", which reminds a lot that of the famous **[Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution)** (also known as the Gaussian distribution). In fact, if we plot the theoretical [probability density function](https://en.wikipedia.org/wiki/Probability_density_function) of a Normal distribution on top of the above histogram, notice how closly it matches the underlying sampled data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc787ffb-cc88-48b5-9b48-85784b109a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = sns.histplot(tosses, bins = bins, stat='probability', label='Coin tosses')\n",
    "\n",
    "# calculate the pdf\n",
    "x0, x1 = ax.get_xlim()  # extract the endpoints for the x-axis\n",
    "x_pdf = np.linspace(x0, x1, 100)\n",
    "y_pdf = stats.norm.pdf(x_pdf, np.mean(tosses), np.std(tosses))\n",
    "\n",
    "ax.plot(x_pdf, y_pdf, 'r', lw=2, label='Normal distr.')                                                   \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c416bce-6025-4f91-87a2-f0153118d02c",
   "metadata": {},
   "source": [
    "More generally, we can say that, for large values of $n$, the distributions of the count of successes as well as the proportion of successes over trials (that is, the probability or proportion of successes) are approximately normal. \n",
    "\n",
    "This result follows from the **[Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)** (CLT) which states that: \n",
    "\n",
    "> Given a large enough sample size $n$, the distribution of the sample mean $\\overline{x}$ will approach a Normal distribution. This is true for a sample of independent random variables from any population distribution, as long as the population has a finite standard deviation $\\sigma$.\n",
    "\n",
    "This theorem is of central importance in statistics and probability theory because it implies that probabilistic and statistical methods that work for Normal distributions can be applicable to situations involving other types of distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3949dd-6787-4ecc-8093-a92d4d472e39",
   "metadata": {},
   "source": [
    "Simply stated, if you have a set of data and: \n",
    "\n",
    "1. you repetedly extract a random sample of its data ($n$ times)\n",
    "2. calculate the average of each sample (the sample mean $\\overline{x}$)\n",
    "\n",
    "then the distribution of the sample means will converge to a Normal distribution (for $n$ large enough). Furthermore, the average of the sample means converges to the mean of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39ca29-cbbc-49e2-8cc8-3a52df060ad5",
   "metadata": {},
   "source": [
    "Let's try to prove this empirically. Inside the `taxis` dataset from the `seaborn` library we can find the `distance` variable, which tells us the distance covered by each cab ride. If we plot a histogram of its distribution, we can clearly see that the variable is leptokurtic and has a positive skew; also, due to the pronounced skewness and presence of extreme values, the mean will clearly be greater than the median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbaa0a6-cb44-472e-bff7-1dcb0f9dc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('taxis')\n",
    "\n",
    "sns.histplot(x = 'distance', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7e406-22ca-474d-851f-d73b0f32faa5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.distance.describe()[['mean', '50%', 'std']].append(pd.Series({'iqr':df.distance.describe()[['75%']].values[0]-df.distance.describe()[['25%']].values[0], \n",
    "                                                                 'skew':df.distance.skew(), \n",
    "                                                                 'kurt':df.distance.kurtosis()\n",
    "                                                                }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fccdf-4a07-4d56-a456-378b3b871218",
   "metadata": {},
   "source": [
    "Let's define a function `sample_means()` that, given a sample `size` and a certain number of `trials` as inputs, produces a list containing the **sample means** as per the CLT algorithm described above.  \n",
    "\n",
    "Then, let's use this function to produce three histograms where we vary the two parameters and, in each iteration, we increase both sample `size` and number of `trials`. It is clear that, as the number of trials increases (that is, $n$), the distribution of the sample means approaches a Normal distribution, as stated by the CLT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d8da8-d906-48f6-a5e5-87ddb7d2f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_means(size, trials): \n",
    "    s_means = []\n",
    "    for n in range(trials): \n",
    "        sample = df.sample(size)['distance']\n",
    "        mean = np.mean(sample)\n",
    "        s_means.append(mean)\n",
    "    return s_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe09816-ff17-45d7-9f7b-d94fa9745157",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [(5, 100), (10, 1000), (100, 10000)]\n",
    "\n",
    "for size, trials in params:\n",
    "    means = sample_means(size, trials)\n",
    "    title_str = 'Sample size: ' + str(size) + ' | Number of trials: ' + str(trials) + ' | Average of sample means:' + str(round(np.mean(means), 2))\n",
    "    sns.histplot(means).set_title(title_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c4b82-8e38-4e81-b7a9-28ee1d9e6f17",
   "metadata": {},
   "source": [
    "This method is also known among statisticians and data scientists as **[bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3c56d-fecc-405d-8fac-6baf670cbd1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f0474-9fbd-4d81-aea7-da8fdfbef991",
   "metadata": {},
   "source": [
    "We said that the average of the sample means converges to the mean of the population. So, if we were to take the average of the `means` list from our last iteration (100 samples, 10,000 trials), we would get an **estimate** of the mean of the population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6966ea-a4de-45f7-85ba-04528b28148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68dab7a-c303-405c-a808-807c9f076039",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d3f33-142b-42bf-bc2e-a292f1fc8bc3",
   "metadata": {},
   "source": [
    "It is common to place way too much faith in an estimate when it is presented as a single number (that is, a point estimate). Statisticians, as well as most statistical software, usually present an estimate not just as a single number but coupled with a range, best known as **[confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval)** (CI).\n",
    "\n",
    "Confidence intervals always come with a *level of confidence*, usually 90% or 95%. As an example, a 95% confidence interval **encloses the central 95% of the bootstrap sampling distribution** of a sample statistic (like the sample means we just calculated). \n",
    "\n",
    "So, given the `means` data, the 95% confidence iterval for those sample means is given by the 2.5th and 97.5th percentiles of their distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a11db-037f-44b8-a7a3-4add9b5bb323",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.percentile(means, 2.5), 2), round(np.percentile(means, 97.5), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d107b-d66d-4c2c-b236-ffffc5257092",
   "metadata": {},
   "source": [
    "The one we just saw is an empirical way to construct a confidence interval. There is also an analytical way to find confidence intervals; the formula for the 95% CI is the following: \n",
    "\n",
    "$$\n",
    "    CI = \\overline{x} \\pm 1.96 \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "where $\\overline{x}$ = sample mean, $s$ = sample standard deviation and 1.96 is the [z-score](https://en.wikipedia.org/wiki/97.5th_percentile_point) for the 97.5 percentile point.\n",
    "\n",
    "One way to compute confidence intervals in Python is through `scipy`'s function `stats.norm.interval()`. As you can see from the output in the next cell, the two methods produce similar results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717902e7-c9c6-4736-a80a-86dfee5a0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, upper = stats.norm.interval(0.95, loc=np.mean(means), scale=np.std(means))\n",
    "round(lower, 2), round(upper, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e8727-8d1d-4977-86e7-a10e3fe321aa",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8068c2a-f5f0-4b19-b1df-6cbc1ed3fb46",
   "metadata": {},
   "source": [
    "It is only fair to dedicate some words to the bell-shaped normal distribution, bing so iconic in traditional statistics. It is a common misconception that the normal distribution is called that because most data follows a normal distribution. Most of the variables used in real life projects are not normally distributed. That said, the utility of the normal distribution derives, as we just saw, from the fact that **many statistics are normally distributed in their sampling distribution**. Even so, in practical business applications, assumptions of normality are generally a last resort, used when empirical probability distributions, or bootstrap distributions, are not available. \n",
    "\n",
    "The `numpy` function to sample data from a normal distribution is `np.random.normal()`, which takes three parameters: \n",
    "\n",
    "- `loc`: mean of the distribution\n",
    "- `scale`: standard deviation of the distribution\n",
    "- `size`: number of extractions from the distribution\n",
    "\n",
    "As an example, let's say we'd like to create an object `heights` containing simulated data of population heights. Since the height of a population follows a Normal distribution, we can extract a sample of 1000 observations from a Normal distribution having mean 170 and standard deviation 10. The \n",
    "\n",
    "following is the standard statistical notation to describe such a random variable: \n",
    "\n",
    "$$\n",
    "    heights \\sim N(\\mu, \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dbcd04-49ae-4e01-82d1-727ba3fcff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = np.random.normal(170, 10, 1000)\n",
    "heights[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4207df-bf42-4233-9e72-096820534cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(heights, fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdf37d-1380-476b-8a50-de8ada6d280d",
   "metadata": {},
   "source": [
    "A **standard normal distribution** is one in which the units on the x-axis are expressed in terms of standard deviations away from the mean. That is, you subtract the mean from a data value and then divide by the standard deviation: \n",
    "\n",
    "$$\n",
    "    z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "This practice is also known as normalization or standardization and the transformed Normal Distribution value is termed a **z-score**. \n",
    "\n",
    "A **QQ-Plot** is used to visually determine how close a sample is to the Normal distribution. The QQ-Plot orders the z-scores from low to high, and plots each value’s z-score on the y-axis; the x-axis is the corresponding thoretical quantile of a Normal distribution for that value’s rank.\n",
    "\n",
    "The `stats.probplot()` function from the `scipy` library allows us to produce a QQ-Plot from our data. If the points roughly fall on the diagonal line, then the sample distribution can be considered close to normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6154abc-775a-49e2-879b-350a90a7cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(heights, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800348f-21b7-42ee-bd5f-301f37d830a0",
   "metadata": {},
   "source": [
    "It should come at no surprise that the `heights` data is normally distributed, since we extracted the data points from a Normal distribution. Let's see if the `distance` variable from the `taxis` dataset follows a similar distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33693c28-f14d-4aef-a25d-a698162d5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df.distance, dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a00a2cf-ab9d-4eb2-8793-84bba978cb7c",
   "metadata": {},
   "source": [
    "As we've observed before, this variable's distribution is positively skewed and leptokurtic, so it definitely not Normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d52ee-af88-4191-945f-b408a8b5f2a0",
   "metadata": {},
   "source": [
    "### Poisson distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b7d45-d98e-4d88-b346-d24f78641928",
   "metadata": {},
   "source": [
    "Many processes produce **random events at a given rate** which can be **spread over time**, such as: \n",
    "\n",
    "- the visits to a website \n",
    "- the calls received by a call center, \n",
    "\n",
    "or can be **spread over space** like: \n",
    "\n",
    "- the number of meteorites with a diameter greater than 1 meter that strike Earth in a year \n",
    "- the number of chewing gums on a single tile of a sidewalk.\n",
    "\n",
    "The **[Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution)** expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a **known constant mean rate** and **independently of the time** since the last event. \n",
    "\n",
    "For example, let's say that on average 90 cars arrive at a highway tollbooth every hour, 24 hours a day. The arrivals are independent, that is, receiving one does not change the probability of when the next one will arrive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389af23c-572e-4d3a-b765-3595fe4b02e0",
   "metadata": {},
   "source": [
    "The `np.random.poisson()` function allows us to extract samples from a Poisson distribution by specifying the average rate and the sample size. If we keep the example from before, we could simulate the number of cars arriving every minute at the tollbooth, using a mean rate of $90/60 = 1.5$ cars per minute and generating a sample of $60*24 = 1440$ minutes in a day: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d403bd-e284-40ef-81f4-04e9f556a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = np.random.poisson(90/60, 60*24)\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0c6f7-b517-42e7-84cd-3e344f92fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "binz = [el-0.5 for el in list(set(cars))]\n",
    "sns.histplot(cars, bins = binz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cddbc-8c9c-4ea4-a5e6-71d33a76653f",
   "metadata": {},
   "source": [
    "### Footnote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ed726-e85e-43b0-bb9a-2a17c9e8af41",
   "metadata": {},
   "source": [
    "This is by no mean a complete course on statistics and probability, the purpose is not to make you a statistician, but rather to give you the main intuitions behind the main principles and concepts of these disciplines. \n",
    "\n",
    "For a more detailed account of the these topics, check out [this GitHub repository](https://github.com/Probability-Statistics-Jupyter-Notebook/probability-statistics-notebook/tree/master/notebook-for-learning), where you'll find more info and details (in a Jupyter Notebooks format). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
